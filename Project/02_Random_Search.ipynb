{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project - Regressors\n",
    "\n",
    "## Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "\n",
    "from operator import itemgetter, attrgetter\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare parallel kernel\n",
    "\n",
    "*Install [here](https://ipyparallel.readthedocs.io/en/latest/), define the number of engines and click '**Start**' in the* **iPython Clusters** *tab.*\n",
    "\n",
    "Import parallel computing libraries and register processors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipyparallel import Client\n",
    "from ipyparallel.joblib import IPythonParallelBackend\n",
    "from joblib import Parallel, parallel_backend, register_parallel_backend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On Noto, run `ipcontroller --ip=\"*\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = Client(profile='default')\n",
    "print('profile:', c.profile)\n",
    "print(\"IDs:\", c.ids) # Process id numbers\n",
    "bview = c.load_balanced_view()\n",
    "register_parallel_backend('ipyparallel',\n",
    "                          lambda : IPythonParallelBackend(view=bview))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Function definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pp_rf(test_size):\n",
    "    \n",
    "    list_of_files = glob.glob('50_by_100/Full*.csv') # * means all if need specific format then *.csv\n",
    "    latest_file = max(list_of_files, key=os.path.getctime)\n",
    "    \n",
    "    print('Latest file : ', latest_file)\n",
    "\n",
    "    df_raw = pd.read_csv(latest_file, index_col=0)\n",
    "    #df_raw.sort_index(inplace = True, ascending = True)\n",
    "    #df_raw.sort_index(inplace = True, axis = 1)\n",
    "\n",
    "    y = df_raw.COVID.copy()\n",
    "    X = df_raw.drop(columns = ['COVID']).copy()\n",
    "    \n",
    "    X_types = dict(X.dtypes)\n",
    "    features = list(X.columns)\n",
    "    \n",
    "    train = np.random.rand(len(df_raw))> test_size\n",
    "\n",
    "    X_train = X[train]\n",
    "    X_test = X[~train]\n",
    "\n",
    "    y_train = y[train].tolist()\n",
    "    y_test = y[~train].tolist()\n",
    "\n",
    "    return X, X_train, X_test, y, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define plotting functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_importance(feature_importance_sorted, n, type_of_search):\n",
    "    \n",
    "    plt.figure(figsize=(15,10))\n",
    "    x = np.arange(n)\n",
    "    y = [feature_importance_sorted[i][1] for i in range(n)]\n",
    "    labels = [feature_importance_sorted[i][0] for i in range(n)]\n",
    "    ax = sns.barplot(y,x,orient=\"h\");\n",
    "    plt.xlabel(\"Importance fraction\", fontsize = 15)\n",
    "    ax.set_xticklabels(['{:,.0%}'.format(x) for x in ax.get_xticks()], fontsize = 15)\n",
    "    plt.yticks(x,labels, fontsize = 15)\n",
    "    plt.title('Most important feature: {}'.format(type_of_search), fontsize = 15)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('Feature rank '+type_of_search+'.png')\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cumulative(feature_importance_sorted, type_of_search):\n",
    "    sorted_importances = [importance[1] for importance in feature_importance_sorted]\n",
    "    sorted_features = [importance[0] for importance in feature_importance_sorted]\n",
    "    x_values = list(range(len(feature_importance_sorted)))\n",
    "\n",
    "    cumulative_importances = np.cumsum(sorted_importances)\n",
    "    \n",
    "    plt.figure(figsize=(15,5))\n",
    "    plt.plot(x_values, cumulative_importances, 'g-')\n",
    "    plt.hlines(y = 0.95, xmin=0, xmax=len(sorted_importances), color = 'r', linestyles = 'dashed')\n",
    "    plt.xlabel('Number of variables', fontsize = 15)\n",
    "    plt.ylabel('Cumulative Importance', fontsize = 15)\n",
    "    plt.title('Cumulative Importances', fontsize = 15)\n",
    "    \n",
    "    plt.xticks(fontsize = 15)\n",
    "    plt.yticks(fontsize = 15)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('Cumulative importance '+type_of_search+'.png')\n",
    "    plt.show()\n",
    "    \n",
    "    limit = np.where(cumulative_importances > 0.95)[0][0] + 1\n",
    "    print('Number of features for 95% importance:', limit)\n",
    "    \n",
    "    return limit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Regressor\n",
    "\n",
    "We will compare two methods, which are grid search and random search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, X_train, X_test, y, y_train, y_test = pp_rf(0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_reg = RandomForestRegressor(n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Search\n",
    "\n",
    "After having explored a grid search, we can adopt another approach. Instead of searching for each value, let's give our model more parameters as inputs, but instead let it choose randomly at each iteration one value for each parameter. It will then be evaluated again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = range(10,1000,50)\n",
    "criterion = ['mse', 'mae']\n",
    "max_depth = range(5,20)\n",
    "min_samples_split = range(2,10,2)\n",
    "min_samples_leaf = range(1,2)\n",
    "max_features = ['sqrt', 'log2', None]\n",
    "bootstrap = [True]\n",
    "\n",
    "random_parameters = {'n_estimators' : n_estimators,\n",
    "                     'criterion' : criterion,\n",
    "                     'max_depth' : max_depth,\n",
    "                     'min_samples_split' : min_samples_split,\n",
    "                     'min_samples_leaf' : min_samples_leaf,\n",
    "                     'max_features' : max_features,\n",
    "                     'bootstrap' : bootstrap}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "random_reg = RandomizedSearchCV(rf_reg,\n",
    "                                param_distributions = random_parameters,\n",
    "                                n_iter = 5,\n",
    "                                verbose = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with parallel_backend('ipyparallel'):\n",
    "    random_reg.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_best_score = random_reg.best_score_\n",
    "random_best_parameters = random_reg.best_params_\n",
    "random_best_n_estimators = random_best_parameters.get('n_estimators')\n",
    "random_best_criterion = random_best_parameters.get('criterion')\n",
    "random_best_max_depth = random_best_parameters.get('max_depth')\n",
    "random_best_min_samples_split = random_best_parameters.get('min_samples_split')\n",
    "random_best_min_samples_leaf = random_best_parameters.get('min_samples_leaf')\n",
    "random_best_max_features = random_best_parameters.get('max_features')\n",
    "random_best_bootstrap = random_best_parameters.get('bootstrap')\n",
    "\n",
    "\n",
    "print('Random search best_score: {:.5}'.format(random_best_score))\n",
    "\n",
    "print('Random best n_estimators: {}'.format(random_best_n_estimators))\n",
    "print('Random best criterion: {}'.format(random_best_criterion))\n",
    "print('Random best max_depth: {}'.format(random_best_max_depth))\n",
    "print('Random best min_samples_split: {}'.format(random_best_min_samples_split))\n",
    "print('Random best min_samples_leaf: {}'.format(random_best_min_samples_leaf))\n",
    "print('Random best max_features: {}'.format(random_best_max_features))\n",
    "print('Random best bootstrap: {}'.format(random_best_bootstrap))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_best_parameters = {'n_estimators' : [random_best_n_estimators],\n",
    "                        'criterion' : [random_best_criterion],\n",
    "                        'max_depth' : [random_best_max_depth],\n",
    "                        'min_samples_split' : [random_best_min_samples_split],\n",
    "                        'min_samples_leaf' : [random_best_min_samples_leaf],\n",
    "                        'max_features' : [random_best_max_features],\n",
    "                        'bootstrap' : [random_best_bootstrap]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_reg_best = GridSearchCV(rf_reg,\n",
    "                               param_grid = random_best_parameters,\n",
    "                               verbose = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with parallel_backend('ipyparallel'):\n",
    "    random_reg_best.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's apply it to our validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_y_pred = random_reg_best.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Mean Squared Error : {:.5%}\".format(mse(y_test, random_y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mean squared error is very low, so we can take a deeper look at the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_feature_importances = [(list(X.columns)[i], random_reg_best.best_estimator_.feature_importances_[i])\n",
    "                              for i in range(len(list(X.columns)))]\n",
    "random_feature_importances.sort(key=itemgetter(1), reverse = True)\n",
    "plot_importance(random_feature_importances, 20, 'Random search')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "limit = plot_cumulative(random_feature_importances, 'Random search')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We print the $r^2$ score. A value above 0 indicates that the regression is better at predicting the value of y than if it was outputing only the expected value of y regardless of input features. The best possible score is 1.\n",
    "\n",
    "Here the value is close to 0, indicating that the model is slightly better at predicting y than only outputing the expected value, but far from perfect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(r2_score(y_test,random_y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature selection\n",
    "\n",
    "Let's try to run the model again, but this time selecting only the most impacting features to save us some work and let's compare the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_selected_features = [random_feature_importances[i][0]\n",
    "                            for i in range(15)]\n",
    "random_X_train_sel = X_train[random_selected_features]\n",
    "random_X_test_sel = X_test[random_selected_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with parallel_backend('ipyparallel'):\n",
    "    random_reg.fit(random_X_train_sel, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_best_score_sel = random_reg.best_score_\n",
    "random_best_parameters_sel = random_reg.best_params_\n",
    "random_best_n_estimators_sel = random_best_parameters_sel.get('n_estimators')\n",
    "random_best_criterion_sel = random_best_parameters_sel.get('criterion')\n",
    "random_best_max_depth_sel = random_best_parameters_sel.get('max_depth')\n",
    "random_best_min_samples_split_sel = random_best_parameters_sel.get('min_samples_split')\n",
    "random_best_min_samples_leaf_sel = random_best_parameters_sel.get('min_samples_leaf')\n",
    "random_best_max_features_sel = random_best_parameters_sel.get('max_features')\n",
    "random_best_bootstrap_sel = random_best_parameters_sel.get('bootstrap')\n",
    "\n",
    "\n",
    "print('Random search best_score: {:.5}'.format(random_best_score_sel))\n",
    "\n",
    "print('Random best n_estimators: {}'.format(random_best_n_estimators_sel))\n",
    "print('Random best criterion: {}'.format(random_best_criterion_sel))\n",
    "print('Random best max_depth: {}'.format(random_best_max_depth_sel))\n",
    "print('Random best min_samples_split: {}'.format(random_best_min_samples_split_sel))\n",
    "print('Random best min_samples_leaf: {}'.format(random_best_min_samples_leaf_sel))\n",
    "print('Random best max_features: {}'.format(random_best_max_features_sel))\n",
    "print('Random best bootstrap: {}'.format(random_best_bootstrap_sel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_best_parameters_sel = {'n_estimators' : [random_best_n_estimators_sel],\n",
    "                              'criterion' : [random_best_criterion_sel],\n",
    "                              'max_depth' : [random_best_max_depth_sel],\n",
    "                              'min_samples_split' : [random_best_min_samples_split_sel],\n",
    "                              'min_samples_leaf' : [random_best_min_samples_leaf_sel],\n",
    "                              'max_features' : [random_best_max_features_sel],\n",
    "                              'bootstrap' : [random_best_bootstrap_sel]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_reg_best_sel = GridSearchCV(rf_reg,\n",
    "                                   param_grid = random_best_parameters_sel,\n",
    "                                   return_train_score = True,\n",
    "                                   verbose = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with parallel_backend('ipyparallel'):\n",
    "    random_reg_best_sel.fit(random_X_train_sel, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_y_pred_sel = random_reg_best_sel.predict(random_X_test_sel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mean Squared Error: {:.5%}\".format(mse(y_test, random_y_pred_sel)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(r2_score(y_test,random_y_pred_sel))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, the mean squared error and $r^2$ scores are slightly worse than for the full dataset. The computational time has not varied much however."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
