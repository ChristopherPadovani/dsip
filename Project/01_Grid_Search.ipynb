{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project - Regressors\n",
    "\n",
    "## Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "\n",
    "from operator import itemgetter, attrgetter\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare parallel kernel\n",
    "\n",
    "*Install [here](https://ipyparallel.readthedocs.io/en/latest/), define the number of engines and click '**Start**' in the* **iPython Clusters** *tab.*\n",
    "\n",
    "Import parallel computing libraries and register processors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipyparallel import Client\n",
    "from ipyparallel.joblib import IPythonParallelBackend\n",
    "from joblib import parallel_backend, register_parallel_backend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On Noto, run `ipcontroller --ip=\"*\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = Client(profile='default')\n",
    "print('profile:', c.profile)\n",
    "print(\"IDs:\", c.ids) # Process id numbers\n",
    "bview = c.load_balanced_view()\n",
    "register_parallel_backend('ipyparallel',\n",
    "                          lambda : IPythonParallelBackend(view=bview))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Function definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pp_rf(test_size):\n",
    "    \n",
    "    list_of_files = glob.glob('50_by_100/Full*.csv') # * means all if need specific format then *.csv\n",
    "    latest_file = max(list_of_files, key=os.path.getctime)\n",
    "    \n",
    "    print(latest_file)\n",
    "\n",
    "    df_raw = pd.read_csv(latest_file, index_col=0)\n",
    "    df_raw.sort_index(inplace = True, ascending = True)\n",
    "    df_raw.sort_index(inplace = True, axis = 1)\n",
    "\n",
    "    y = df_raw.COVID.copy()\n",
    "    X = df_raw.drop(columns = ['COVID']).copy()\n",
    "    \n",
    "    X_types = dict(X.dtypes)\n",
    "    features = list(X.columns)\n",
    "    \n",
    "    train = np.random.rand(len(df_raw))> test_size\n",
    "\n",
    "    X_train = X[train]\n",
    "    X_test = X[~train]\n",
    "\n",
    "    y_train = y[train].tolist()\n",
    "    y_test = y[~train].tolist()\n",
    "\n",
    "    return X, X_train, X_test, y, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_importance(feature_importance_sorted, n, type_of_search):\n",
    "    \n",
    "    plt.figure(figsize=(25,5))\n",
    "    x = np.arange(n)\n",
    "    y = [feature_importance_sorted[i][1] for i in range(n)]\n",
    "    labels = [feature_importance_sorted[i][0] for i in range(n)]\n",
    "    ax = sns.barplot(y,x,orient=\"h\");\n",
    "    plt.xlabel(\"Importance fraction\", fontsize = 12)\n",
    "    ax.set_xticklabels(['{:,.0%}'.format(x) for x in ax.get_xticks()])\n",
    "    plt.yticks(x,labels, fontsize = 15)\n",
    "    plt.title('Most important feature: {}'.format(type_of_search), fontsize = 15)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Regressor\n",
    "\n",
    "We will compare two methods, which are grid search and random search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, X_train, X_test, y, y_train, y_test = pp_rf(0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_reg = RandomForestRegressor(n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid search\n",
    "\n",
    "To avoid having too high a computational time, we will focus on 2 of the mot important parameters that are max depth and the number of estimators.\n",
    "\n",
    "#### Max Depth\n",
    "\n",
    "This parameter is the depth of the trees, which is one of the most important. We range it between 4 (anything lower seems too low and increases computational time without much results) and 15.\n",
    "\n",
    "#### Number of estimators\n",
    "\n",
    "This parameter is the number of trees that are going to be generated. Here the choice of the number of trees will mostly affect the computational time. Let's set the values between 100 and 5'000 and see the effects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#n_estimators = range(10,5000,50)\n",
    "n_estimators = [100, 200, 500, 1000, 2000, 5000]\n",
    "#criterion = ['mse', 'mae']\n",
    "criterion = ['mse']\n",
    "max_depth = range(5,50,10)\n",
    "#min_samples_split = range(2,100,2)\n",
    "min_samples_split = [2]\n",
    "#min_samples_leaf = range(2,100,2)\n",
    "min_samples_leaf = [2]\n",
    "#max_features = ['sqrt', 'log2', None]\n",
    "max_features = ['sqrt']\n",
    "#bootstrap = [True, False]\n",
    "bootstrap = [True]\n",
    "\n",
    "grid_parameters = {'n_estimators' : n_estimators,\n",
    "                   'criterion' : criterion,\n",
    "                   'max_depth' : max_depth,\n",
    "                   'min_samples_split' : min_samples_split,\n",
    "                   'min_samples_leaf' : min_samples_leaf,\n",
    "                   'max_features' : max_features,\n",
    "                   'bootstrap' : bootstrap}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use the default 5 folds of cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_reg = GridSearchCV(rf_reg,\n",
    "                        param_grid = grid_parameters,\n",
    "                        return_train_score = True,\n",
    "                        verbose = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with parallel_backend('ipyparallel'):\n",
    "    grid_reg.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check which model is the best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_best_score = grid_reg.best_score_\n",
    "grid_best_parameters = grid_reg.best_params_\n",
    "grid_best_n_estimators = grid_best_parameters.get('n_estimators')\n",
    "grid_best_criterion = grid_best_parameters.get('criterion')\n",
    "grid_best_max_depth = grid_best_parameters.get('max_depth')\n",
    "grid_best_min_samples_split = grid_best_parameters.get('min_samples_split')\n",
    "grid_best_min_samples_leaf = grid_best_parameters.get('min_samples_leaf')\n",
    "grid_best_max_features = grid_best_parameters.get('max_features')\n",
    "grid_best_bootstrap = grid_best_parameters.get('bootstrap')\n",
    "\n",
    "\n",
    "print('Grid search best_score: {:.5}'.format(grid_best_score))\n",
    "\n",
    "print('Grid best n_estimators: {}'.format(grid_best_n_estimators))\n",
    "print('Grid best criterion: {}'.format(grid_best_criterion))\n",
    "print('Grid best max_depth: {}'.format(grid_best_max_depth))\n",
    "print('Grid best min_samples_split: {}'.format(grid_best_min_samples_split))\n",
    "print('Grid best min_samples_leaf: {}'.format(grid_best_min_samples_leaf))\n",
    "print('Grid best max_features: {}'.format(grid_best_max_features))\n",
    "print('Grid best bootstrap: {}'.format(grid_best_bootstrap))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_best_parameters = {'n_estimators' : [grid_best_n_estimators],\n",
    "                        'criterion' : [grid_best_criterion],\n",
    "                        'max_depth' : [grid_best_max_depth],\n",
    "                        'min_samples_split' : [grid_best_min_samples_split],\n",
    "                        'min_samples_leaf' : [grid_best_min_samples_leaf],\n",
    "                        'max_features' : [grid_best_max_features],\n",
    "                        'bootstrap' : [grid_best_bootstrap]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_reg_best = GridSearchCV(rf_reg,\n",
    "                             param_grid = grid_best_parameters,\n",
    "                             return_train_score = True,\n",
    "                             verbose = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with parallel_backend('ipyparallel'):\n",
    "    grid_reg_best.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's apply it to our validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_y_pred = grid_reg_best.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Accuracy: {:.2%}\".format(mse(y_test, grid_y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given this accuracy, we can take a deeper look into the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_feature_importances = [(list(X.columns)[i], grid_reg_best.best_estimator_.feature_importances_[i])\n",
    "                            for i in range(len(list(X.columns)))]\n",
    "grid_feature_importances.sort(key=itemgetter(1), reverse = True)\n",
    "plot_importance(grid_feature_importances, 20, 'Grid search')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(r2_score(y_test,grid_y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature selection\n",
    "\n",
    "Let's try to run the model again, but this time selecting only the most impacting features to save us some work and let's compare the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_selected_features = [grid_feature_importances[i][0]\n",
    "                          for i in range(15)]\n",
    "grid_X_train_sel = X_train[grid_selected_features]\n",
    "grid_X_test_sel = X_test[grid_selected_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with parallel_backend('ipyparallel'):\n",
    "    grid_reg.fit(grid_X_train_sel, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_best_score_sel = grid_reg.best_score_\n",
    "grid_best_parameters_sel = grid_reg.best_params_\n",
    "grid_best_n_estimators_sel = grid_best_parameters_sel.get('n_estimators')\n",
    "grid_best_criterion_sel = grid_best_parameters_sel.get('criterion')\n",
    "grid_best_max_depth_sel = grid_best_parameters_sel.get('max_depth')\n",
    "grid_best_min_samples_split_sel = grid_best_parameters_sel.get('min_samples_split')\n",
    "grid_best_min_samples_leaf_sel = grid_best_parameters_sel.get('min_samples_leaf')\n",
    "grid_best_max_features_sel = grid_best_parameters_sel.get('max_features')\n",
    "grid_best_bootstrap_sel = grid_best_parameters_sel.get('bootstrap')\n",
    "\n",
    "\n",
    "print('Grid search best_score: {:.5}'.format(grid_best_score_sel))\n",
    "\n",
    "print('Grid best n_estimators: {}'.format(grid_best_n_estimators_sel))\n",
    "print('Grid best criterion: {}'.format(grid_best_criterion_sel))\n",
    "print('Grid best max_depth: {}'.format(grid_best_max_depth_sel))\n",
    "print('Grid best min_samples_split: {}'.format(grid_best_min_samples_split_sel))\n",
    "print('Grid best min_samples_leaf: {}'.format(grid_best_min_samples_leaf_sel))\n",
    "print('Grid best max_features: {}'.format(grid_best_max_features_sel))\n",
    "print('Grid best bootstrap: {}'.format(grid_best_bootstrap_sel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_best_parameters_sel = {'n_estimators' : [grid_best_n_estimators_sel],\n",
    "                            'criterion' : [grid_best_criterion_sel],\n",
    "                            'max_depth' : [grid_best_max_depth_sel],\n",
    "                            'min_samples_split' : [grid_best_min_samples_split_sel],\n",
    "                            'min_samples_leaf' : [grid_best_min_samples_leaf_sel],\n",
    "                            'max_features' : [grid_best_max_features_sel],\n",
    "                            'bootstrap' : [grid_best_bootstrap_sel]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_reg_best_sel = GridSearchCV(rf_reg,\n",
    "                                 param_grid = grid_best_parameters_sel,\n",
    "                                 return_train_score = True,\n",
    "                                 verbose = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with parallel_backend('ipyparallel'):\n",
    "    grid_reg_best_sel.fit(grid_X_train_sel, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_y_pred_sel = grid_reg_best_sel.predict(grid_X_test_sel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy: {:.2%}\".format(mse(y_test, grid_y_pred_sel)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(r2_score(y_test,grid_y_pred_sel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
